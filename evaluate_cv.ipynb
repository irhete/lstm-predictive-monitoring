{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"/storage/hpc_irheta/bpic2013/\"\n",
    "folds_dir = os.path.join(data_path, \"folds\")\n",
    "n_folds = 5\n",
    "weights_file_template = \"bpic2013/bpic2013_fold%s_weights*.hdf5\"\n",
    "generated_traces_ratios = [1, 2, 5, 10] # ratios to single fold size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case_id_col = \"Case ID\"\n",
    "activity_col = \"Activity\"\n",
    "timestamp_col = \"Complete Timestamp\"\n",
    "cat_cols = [activity_col]\n",
    "start_event = \"START\"\n",
    "end_event = \"END\"\n",
    "\n",
    "# LSTM params\n",
    "lstmsize = 48\n",
    "dropout = 0.5\n",
    "optim = 'rmsprop'\n",
    "loss = 'categorical_crossentropy'\n",
    "nb_epoch = 10\n",
    "activation='softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_event_as_onehot(event_idx, data_dim):\n",
    "    event = np.zeros(data_dim)\n",
    "    event[event_idx] = 1\n",
    "    return event\n",
    "\n",
    "def generate_trace(start_idx, data_dim, end_event, time_dim, col_idxs):\n",
    "    event_idx = start_idx\n",
    "    events = get_event_as_onehot(event_idx, data_dim)[np.newaxis,:]\n",
    "    trace = []\n",
    "    while col_idxs[event_idx] != end_event:# and len(trace) < max_events:\n",
    "        event_idx = np.random.choice(len(col_idxs), 1, p=model.predict(pad_sequences(events[np.newaxis,:,:], maxlen=time_dim))[0])[0]\n",
    "        event = get_event_as_onehot(event_idx, data_dim)\n",
    "        events = np.vstack([events, get_event_as_onehot(event_idx, data_dim)])\n",
    "        trace.append(col_idxs[event_idx])\n",
    "    return tuple(trace[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no 0:\n",
      "Number of distinct traces in train set: 1902, val set: 549, total: 2278\n",
      "Number of distinct traces in val set not present in train set: 376\n",
      "Total traces generated: 1511, ratio to fold size: 1\n",
      "Number of existing traces in training set: 1093, distinct: 144\n",
      "Number of existing traces in validation set: 11, distinct: 8\n",
      "Number of new traces: 407, distinct: 364\n",
      "\n",
      "\n",
      "Total traces generated: 3022, ratio to fold size: 2\n",
      "Number of existing traces in training set: 2163, distinct: 197\n",
      "Number of existing traces in validation set: 19, distinct: 11\n",
      "Number of new traces: 840, distinct: 710\n",
      "\n",
      "\n",
      "Total traces generated: 7555, ratio to fold size: 5\n",
      "Number of existing traces in training set: 5390, distinct: 269\n",
      "Number of existing traces in validation set: 55, distinct: 27\n",
      "Number of new traces: 2110, distinct: 1610\n",
      "\n",
      "\n",
      "Total traces generated: 15110, ratio to fold size: 10\n",
      "Number of existing traces in training set: 10677, distinct: 330\n",
      "Number of existing traces in validation set: 112, distinct: 41\n",
      "Number of new traces: 4321, distinct: 2987\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold no 1:\n",
      "Number of distinct traces in train set: 1885, val set: 578, total: 2278\n",
      "Number of distinct traces in val set not present in train set: 393\n",
      "Total traces generated: 1511, ratio to fold size: 1\n",
      "Number of existing traces in training set: 965, distinct: 129\n",
      "Number of existing traces in validation set: 8, distinct: 5\n",
      "Number of new traces: 538, distinct: 486\n",
      "\n",
      "\n",
      "Total traces generated: 3022, ratio to fold size: 2\n",
      "Number of existing traces in training set: 1931, distinct: 181\n",
      "Number of existing traces in validation set: 15, distinct: 10\n",
      "Number of new traces: 1076, distinct: 933\n",
      "\n",
      "\n",
      "Total traces generated: 7555, ratio to fold size: 5\n",
      "Number of existing traces in training set: 4868, distinct: 248\n",
      "Number of existing traces in validation set: 56, distinct: 25\n",
      "Number of new traces: 2631, distinct: 2116\n",
      "\n",
      "\n",
      "Total traces generated: 15110, ratio to fold size: 10\n",
      "Number of existing traces in training set: 9697, distinct: 300\n",
      "Number of existing traces in validation set: 128, distinct: 33\n",
      "Number of new traces: 5285, distinct: 3950\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold no 2:\n",
      "Number of distinct traces in train set: 1894, val set: 564, total: 2278\n",
      "Number of distinct traces in val set not present in train set: 384\n",
      "Total traces generated: 1511, ratio to fold size: 1\n",
      "Number of existing traces in training set: 964, distinct: 139\n",
      "Number of existing traces in validation set: 21, distinct: 14\n",
      "Number of new traces: 526, distinct: 473\n",
      "\n",
      "\n",
      "Total traces generated: 3022, ratio to fold size: 2\n",
      "Number of existing traces in training set: 1940, distinct: 185\n",
      "Number of existing traces in validation set: 46, distinct: 17\n",
      "Number of new traces: 1036, distinct: 885\n",
      "\n",
      "\n",
      "Total traces generated: 7555, ratio to fold size: 5\n",
      "Number of existing traces in training set: 4868, distinct: 257\n",
      "Number of existing traces in validation set: 121, distinct: 26\n",
      "Number of new traces: 2566, distinct: 2065\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3b257640f301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_generated_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_traces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mn_existing_in_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-1c7d6007b338>\u001b[0m in \u001b[0;36mgenerate_trace\u001b[0;34m(start_idx, data_dim, end_event, time_dim, col_idxs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcol_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevent_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mend_event\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# and len(trace) < max_events:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mevent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_event_as_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_event_as_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1197\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    951\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold_nr in range(n_folds):\n",
    "    lstm_weights_file = glob.glob(weights_file_template%(fold_nr))[-1]\n",
    "    \n",
    "    # Read the relevant folds\n",
    "    fold_files = os.listdir(folds_dir)\n",
    "    data = pd.DataFrame()\n",
    "    for file_idx in range(len(fold_files)):\n",
    "        if file_idx != fold_nr:\n",
    "            tmp = pd.read_csv(os.path.join(folds_dir, fold_files[file_idx]), sep=\";\")\n",
    "            data = pd.concat([data, tmp], axis=0)\n",
    "        else:\n",
    "            val_data = pd.read_csv(os.path.join(folds_dir, fold_files[file_idx]), sep=\";\")\n",
    "\n",
    "    # which traces exist in the train and val logs\n",
    "    train_traces = set()\n",
    "    grouped = data.groupby(case_id_col)\n",
    "    for name, group in grouped:\n",
    "        group = group.sort_values(timestamp_col)\n",
    "        train_traces.add(tuple(group[activity_col]))\n",
    "        \n",
    "    val_traces = set()\n",
    "    grouped_val = val_data.groupby(case_id_col)\n",
    "    for name, group in grouped_val:\n",
    "        group = group.sort_values(timestamp_col)\n",
    "        val_traces.add(tuple(group[activity_col]))\n",
    "\n",
    "    # prepare data\n",
    "    cat_data = pd.get_dummies(data[cat_cols])\n",
    "    dt_final = pd.concat([data[[case_id_col, timestamp_col]], cat_data], axis=1).fillna(0)\n",
    "    dt_final[start_event] = 0\n",
    "    dt_final[end_event] = 0\n",
    "    grouped = dt_final.groupby(case_id_col)\n",
    "    n_existing_traces = len(grouped)\n",
    "\n",
    "    # generate dict of activity idxs\n",
    "    col_idxs = {idx:col.replace(\"%s_\"%activity_col, \"\") for idx, col in enumerate(cat_data.columns)}\n",
    "    col_idxs[len(col_idxs)] = start_event\n",
    "    col_idxs[len(col_idxs)] = end_event\n",
    "    start_idx = col_idxs.keys()[col_idxs.values().index(start_event)]\n",
    "\n",
    "\n",
    "    # load LSTM model\n",
    "    max_events = grouped.size().max()\n",
    "    data_dim = dt_final.shape[1] - 2\n",
    "    time_dim = max_events + 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstmsize, input_shape=(time_dim, data_dim)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(data_dim, activation=activation))\n",
    "    model.compile(loss=loss, optimizer=optim)\n",
    "\n",
    "    model.load_weights(lstm_weights_file)\n",
    "    \n",
    "    print(\"Fold no %s:\"%fold_nr)\n",
    "    print(\"Number of distinct traces in train set: %s, val set: %s, total: %s\"%(len(train_traces), len(val_traces), len(train_traces.union(val_traces))))\n",
    "    print(\"Number of distinct traces in val set not present in train set: %s\"%(len(val_traces.difference(train_traces))))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for generated_traces_ratio in generated_traces_ratios:\n",
    "        n_generated_traces = len(grouped_val) * generated_traces_ratio\n",
    "    \n",
    "        # generate new traces\n",
    "        n_existing_in_train = defaultdict(int)\n",
    "        n_existing_in_validation = defaultdict(int)\n",
    "        n_new = defaultdict(int)\n",
    "        np.random.seed(22)\n",
    "        for i in range(n_generated_traces):\n",
    "            trace = generate_trace(start_idx, data_dim, end_event, time_dim, col_idxs)\n",
    "            if trace in train_traces:\n",
    "                n_existing_in_train[trace] += 1\n",
    "            elif trace in val_traces:\n",
    "                n_existing_in_validation[trace] += 1\n",
    "            else:\n",
    "                n_new[trace] += 1\n",
    "                \n",
    "        print(\"Total traces generated: %s, ratio to fold size: %s\"%(n_generated_traces, generated_traces_ratio))\n",
    "        print(\"Number of existing traces in training set: %s, distinct: %s\"%(sum(n_existing_in_train.values()), len(n_existing_in_train)))\n",
    "        print(\"Number of existing traces in validation set: %s, distinct: %s\"%(sum(n_existing_in_validation.values()), len(n_existing_in_validation)))\n",
    "        print(\"Number of new traces: %s, distinct: %s\"%(sum(n_new.values()), len(n_new)))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_log_template = \"/storage/hpc_irheta/bpic2013/BPIC13_i_generated_fold%s_sizeratio%s.csv\"\n",
    "\n",
    "# generate log\n",
    "for fold_nr in range(1):\n",
    "    lstm_weights_file = glob.glob(weights_file_template%(fold_nr))[-1]\n",
    "    \n",
    "    # Read the relevant folds\n",
    "    fold_files = os.listdir(folds_dir)\n",
    "    data = pd.DataFrame()\n",
    "    for file_idx in range(len(fold_files)):\n",
    "        if file_idx != fold_nr:\n",
    "            tmp = pd.read_csv(os.path.join(folds_dir, fold_files[file_idx]), sep=\";\")\n",
    "            data = pd.concat([data, tmp], axis=0)\n",
    "        else:\n",
    "            val_data = pd.read_csv(os.path.join(folds_dir, fold_files[file_idx]), sep=\";\")\n",
    "\n",
    "    grouped_val = val_data.groupby(case_id_col)\n",
    "\n",
    "    # prepare data\n",
    "    cat_data = pd.get_dummies(data[cat_cols])\n",
    "    dt_final = pd.concat([data[[case_id_col, timestamp_col]], cat_data], axis=1).fillna(0)\n",
    "    dt_final[start_event] = 0\n",
    "    dt_final[end_event] = 0\n",
    "    grouped = dt_final.groupby(case_id_col)\n",
    "    n_existing_traces = len(grouped)\n",
    "\n",
    "    # generate dict of activity idxs\n",
    "    col_idxs = {idx:col.replace(\"%s_\"%activity_col, \"\") for idx, col in enumerate(cat_data.columns)}\n",
    "    col_idxs[len(col_idxs)] = start_event\n",
    "    col_idxs[len(col_idxs)] = end_event\n",
    "    start_idx = col_idxs.keys()[col_idxs.values().index(start_event)]\n",
    "\n",
    "\n",
    "    # load LSTM model\n",
    "    max_events = grouped.size().max()\n",
    "    data_dim = dt_final.shape[1] - 2\n",
    "    time_dim = max_events + 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstmsize, input_shape=(time_dim, data_dim)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(data_dim, activation=activation))\n",
    "    model.compile(loss=loss, optimizer=optim)\n",
    "\n",
    "    model.load_weights(lstm_weights_file)\n",
    "    \n",
    "    \n",
    "    for generated_traces_ratio in [5]:\n",
    "        with open(generated_log_template%(fold_nr, generated_traces_ratio), \"w\") as fout:\n",
    "            fout.write(\"%s,%s,%s\\n\"%(\"Case ID\", \"Activity\", \"Complete Timestamp\"))\n",
    "            n_generated_traces = len(grouped_val) * generated_traces_ratio\n",
    "\n",
    "            # generate new traces\n",
    "            np.random.seed(22)\n",
    "            for i in range(n_generated_traces):\n",
    "                trace = generate_trace(start_idx, data_dim, end_event, time_dim, col_idxs)\n",
    "                start_time = datetime.now()\n",
    "                for event in trace:\n",
    "                    timestamp = datetime.strftime(start_time + timedelta(days=1), '%Y/%m/%d %H:%M:%S.%f')\n",
    "                    fout.write(\"%s,%s,%s\\n\"%(\"new%s\"%(i+1), event, timestamp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fold_nr in range(1):\n",
    "    lstm_weights_file = glob.glob(weights_file_template%(fold_nr))[-1]\n",
    "    \n",
    "    # Read the relevant folds\n",
    "    fold_files = os.listdir(folds_dir)\n",
    "    data = pd.DataFrame()\n",
    "    for file_idx in range(len(fold_files)):\n",
    "        if file_idx != fold_nr:\n",
    "            tmp = pd.read_csv(os.path.join(folds_dir, fold_files[file_idx]), sep=\";\")\n",
    "            data = pd.concat([data, tmp], axis=0)\n",
    "        else:\n",
    "            val_data = pd.read_csv(os.path.join(folds_dir, fold_files[file_idx]), sep=\";\")\n",
    "\n",
    "    # which traces exist in the train and val logs\n",
    "    train_traces = set()\n",
    "    grouped = data.groupby(case_id_col)\n",
    "    for name, group in grouped:\n",
    "        group = group.sort_values(timestamp_col)\n",
    "        train_traces.add(tuple(group[activity_col]))\n",
    "        \n",
    "    val_traces = set()\n",
    "    grouped_val = val_data.groupby(case_id_col)\n",
    "    for name, group in grouped_val:\n",
    "        group = group.sort_values(timestamp_col)\n",
    "        val_traces.add(tuple(group[activity_col]))\n",
    "\n",
    "    # prepare data\n",
    "    cat_data = pd.get_dummies(data[cat_cols])\n",
    "    dt_final = pd.concat([data[[case_id_col, timestamp_col]], cat_data], axis=1).fillna(0)\n",
    "    dt_final[start_event] = 0\n",
    "    dt_final[end_event] = 0\n",
    "    grouped = dt_final.groupby(case_id_col)\n",
    "    n_existing_traces = len(grouped)\n",
    "\n",
    "    # generate dict of activity idxs\n",
    "    col_idxs = {idx:col.replace(\"%s_\"%activity_col, \"\") for idx, col in enumerate(cat_data.columns)}\n",
    "    col_idxs[len(col_idxs)] = start_event\n",
    "    col_idxs[len(col_idxs)] = end_event\n",
    "    start_idx = col_idxs.keys()[col_idxs.values().index(start_event)]\n",
    "\n",
    "\n",
    "    # load LSTM model\n",
    "    max_events = grouped.size().max()\n",
    "    data_dim = dt_final.shape[1] - 2\n",
    "    time_dim = max_events + 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstmsize, input_shape=(time_dim, data_dim)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(data_dim, activation=activation))\n",
    "    model.compile(loss=loss, optimizer=optim)\n",
    "\n",
    "    model.load_weights(lstm_weights_file)\n",
    "    \n",
    "    \n",
    "    for generated_traces_ratio in [5]:\n",
    "        n_generated_traces = len(grouped_val) * generated_traces_ratio\n",
    "    \n",
    "        # generate new traces\n",
    "        n_existing_in_train = defaultdict(int)\n",
    "        n_existing_in_validation = defaultdict(int)\n",
    "        n_new = defaultdict(int)\n",
    "        np.random.seed(22)\n",
    "        for i in range(n_generated_traces):\n",
    "            trace = generate_trace(start_idx, data_dim, end_event, time_dim, col_idxs)\n",
    "            if trace in train_traces:\n",
    "                n_existing_in_train[trace] += 1\n",
    "            elif trace in val_traces:\n",
    "                n_existing_in_validation[trace] += 1\n",
    "            else:\n",
    "                n_new[trace] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 37)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\In Call'), 36)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 16)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\In Call'), 15)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 13)\n",
      " \n",
      "(('Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Wait - User', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 12)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Wait - User', 'Accepted\\\\\\\\Wait - User', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 12)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Wait - User', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 11)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Wait - User', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 10)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 10)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 9)\n",
      " \n",
      "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Assigned', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Assigned', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Wait - User', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'), 8)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "i = 0\n",
    "for k, v in sorted(n_new.items(), key=operator.itemgetter(1), reverse=True):\n",
    "    print(k,v)\n",
    "    print(\" \")\n",
    "    if i > 10:\n",
    "        break\n",
    "    i += 1\n",
    "(('Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trie = {}\n",
    "for trace in n_existing_in_validation.keys():\n",
    "    current_trie_position = trie\n",
    "    for i in range(len(trace)):\n",
    "        if trace[i] not in current_trie_position:\n",
    "            current_trie_position[trace[i]] = {}\n",
    "        current_trie_position = current_trie_position[trace[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Path so far: ', ['Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Assigned', 'Accepted\\\\\\\\In Progress', 'Queued\\\\\\\\Awaiting Assignment', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\Assigned', 'Accepted\\\\\\\\In Progress'])\n",
      "\n",
      "\n",
      "('Good traces: ', {'Completed\\\\\\\\Resolved': {'Completed\\\\\\\\Closed': {}}})\n",
      "\n",
      "\n",
      "('Bad trace: ', ['Accepted\\\\\\\\Assigned', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Accepted\\\\\\\\In Progress', 'Completed\\\\\\\\Resolved', 'Completed\\\\\\\\Closed'])\n"
     ]
    }
   ],
   "source": [
    "trace_no = 1\n",
    "current_trace_no = 0\n",
    "for trace in n_new.keys():\n",
    "    if current_trace_no == trace_no:\n",
    "        path = []\n",
    "        current_trie_position = trie\n",
    "        for i in range(len(trace)):\n",
    "            if trace[i] not in current_trie_position:\n",
    "                print(\"Path so far: \", path)\n",
    "                print(\"\\n\")\n",
    "                print(\"Good traces: \", current_trie_position)\n",
    "                print(\"\\n\")\n",
    "                print(\"Bad trace: \", [trace[j] for j in range(i, len(trace))])\n",
    "                break\n",
    "            else:\n",
    "                path.append(trace[i])\n",
    "                current_trie_position = current_trie_position[trace[i]]\n",
    "        break\n",
    "    current_trace_no += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from ete2 import Tree\n",
    "t = Tree( \"((a,b),c);\" )\n",
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ete2 import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named PyQt4.QtGui",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-10fa503a226b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"((a,b),c);\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/ete2/coretype/tree.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, layout, tree_style, name)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \"\"\"\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mete2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreeview\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrawer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m         drawer.show_tree(self, layout=layout,\n\u001b[1;32m   1335\u001b[0m                          tree_style=tree_style, win_name=name)\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/ete2/treeview/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msvg_colors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/ete2/treeview/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtGui\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQtCore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named PyQt4.QtGui"
     ]
    }
   ],
   "source": [
    "t = Tree( \"((a,b),c);\" )\n",
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:132: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~irene.teinemaa/0 or inside your plot.ly account where it is named 'plot from API'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~irene.teinemaa/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "\n",
    "py.sign_in('irene.teinemaa', 'O4pvM5Ko2ywAXqfBWQkk')\n",
    "n = 50\n",
    "x, y, z, s, ew = np.random.rand(5, n)\n",
    "c, ec = np.random.rand(2, n, 4)\n",
    "area_scale, width_scale = 500, 5\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(x, y, c=c,\n",
    "                s=np.square(s)*area_scale,\n",
    "                edgecolor=ec,\n",
    "                linewidth=ew*width_scale)\n",
    "ax.grid()\n",
    "\n",
    "py.iplot_mpl(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DeprecationWarning",
     "evalue": "To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-bee7e783f82c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0migraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0migraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0migraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hpc_irheta/bpm_lstm/lib/python2.7/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m__license__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MIT\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m raise DeprecationWarning(\"To avoid name collision with the igraph project, \"\n\u001b[0m\u001b[1;32m      9\u001b[0m                          \u001b[0;34m\"this visualization library has been renamed to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \"'jgraph'. Please upgrade when convenient.\")\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient."
     ]
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import igraph\n",
    "from igraph import *\n",
    "igraph.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-95be9de149f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnr_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mv_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnr_vertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnr_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 2 stands for children number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Graph' is not defined"
     ]
    }
   ],
   "source": [
    "nr_vertices = 25\n",
    "v_label = map(str, range(nr_vertices))\n",
    "G = Graph.Tree(nr_vertices, 2) # 2 stands for children number\n",
    "lay = G.layout('rt')\n",
    "\n",
    "position = {k: lay[k] for k in range(nr_vertices)}\n",
    "Y = [lay[k][1] for k in range(nr_vertices)]\n",
    "M = max(Y)\n",
    "\n",
    "es = EdgeSeq(G) # sequence of edges\n",
    "E = [e.tuple for e in G.es] # list of edges\n",
    "\n",
    "L = len(position)\n",
    "Xn = [position[k][0] for k in range(L)]\n",
    "Yn = [2*M-position[k][1] for k in range(L)]\n",
    "Xe = []\n",
    "Ye = []\n",
    "for edge in E:\n",
    "    Xe+=[position[edge[0]][0],position[edge[1]][0], None]\n",
    "    Ye+=[2*M-position[edge[0]][1],2*M-position[edge[1]][1], None] \n",
    "\n",
    "labels = v_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
